{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s2GHGJ1K1uh"
   },
   "source": [
    "## Лабораторная работа \"Линейные модели\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wy-GsKMLK1uk"
   },
   "source": [
    "Некоторые задачи в этом ноутбуке надо будет сдавать в [контест](https://new.contest.yandex.ru/60377/start). Когда сдаете туда код, не забудьте сверху прописать все нужные импорты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tjm0ejHfK1ul"
   },
   "source": [
    "Мы рассчитываем, что перед тем, как садиться за этот ноутбук, вы прочитали часть про регрессию главы \"Линейные модели\" хендбука по ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeK9RFdNK1ul"
   },
   "source": [
    "Начнём с загрузки необходимых библиотек и функций.\n",
    "\n",
    "Параметр `seed` будет использоваться далее для инициализации генератора случайных чисел из библиотеки `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ckp6TITPK1ul",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List\n",
    "\n",
    "import sklearn.base\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUoWdYEMK1um"
   },
   "source": [
    "В этом ноутбуке мы будем практиковаться на датасете [\"The Ames Iowa Housing Data\"](https://www.openml.org/d/41211). Здесь собраны описания и цены жилья в городе Эймс, штат Айова. Мы будем решать задачу предсказания цены (`Sale_Price`) по всем остальным признакам.\n",
    "\n",
    "И начнём мы, конечно, с того, что внимательно посмотрим на датасет: какие там есть объекты и какие признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wB9CDwb6K1un",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Uncomment the line below to download data and install necessary packages\n",
    "## Maybe won't work on Windows :(\n",
    "\n",
    "# !pip install numpy pandas sklearn matplotlib\n",
    "# !curl https://api.openml.org/data/get_csv/20649135/file2ed11cebe25.arff > data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-hZmDQonK1un",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>209</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14364</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1371</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>90.0</td>\n",
       "      <td>5400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>1347</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20781</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>262500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>491</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2665</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>719</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10542</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10900</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>450</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>161750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>817</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11425</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1162</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14778</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>224000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>414</td>\n",
       "      <td>30</td>\n",
       "      <td>RM</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8960</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1070</td>\n",
       "      <td>45</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>855</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>102.0</td>\n",
       "      <td>17920</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>1448</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>1432</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4928</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>770</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53504</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>1379</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>83000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>953</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>1240</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>64.0</td>\n",
       "      <td>9037</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>265900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12435</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1020</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3013</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>213490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>839</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9525</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>144000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "208    209          60       RL          NaN    14364   Pave   NaN      IR1   \n",
       "1370  1371          50       RL         90.0     5400   Pave   NaN      Reg   \n",
       "1346  1347          20       RL          NaN    20781   Pave   NaN      IR2   \n",
       "490    491         160       RM          NaN     2665   Pave   NaN      Reg   \n",
       "718    719          60       RL         96.0    10542   Pave   NaN      Reg   \n",
       "214    215          60       RL          NaN    10900   Pave   NaN      IR1   \n",
       "816    817          20       RL          NaN    11425   Pave   NaN      IR1   \n",
       "1161  1162          20       RL          NaN    14778   Pave   NaN      IR1   \n",
       "413    414          30       RM         56.0     8960   Pave  Grvl      Reg   \n",
       "1069  1070          45       RL         60.0     9600   Pave   NaN      Reg   \n",
       "854    855          20       RL        102.0    17920   Pave   NaN      Reg   \n",
       "1447  1448          60       RL         80.0    10000   Pave   NaN      Reg   \n",
       "1431  1432         120       RL          NaN     4928   Pave   NaN      IR1   \n",
       "769    770          60       RL         47.0    53504   Pave   NaN      IR2   \n",
       "1378  1379         160       RM         21.0     1953   Pave   NaN      Reg   \n",
       "952    953          85       RL         60.0     7200   Pave   NaN      Reg   \n",
       "1239  1240          20       RL         64.0     9037   Pave   NaN      IR1   \n",
       "258    259          60       RL         80.0    12435   Pave   NaN      Reg   \n",
       "1019  1020         120       RL         43.0     3013   Pave   NaN      Reg   \n",
       "838    839          20       RL         75.0     9525   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "208          Low    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1370         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1346         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "490          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "718          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "214          Lvl    AllPub  ...        0    NaN  MnPrv        Shed     450   \n",
       "816          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1161         Low    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "413          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1069         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "854          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1447         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1431         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "769          HLS    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1378         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "952          Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1239         HLS    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "258          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1019         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "838          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "208       4   2007        WD         Normal     277000  \n",
       "1370     10   2009        WD         Normal     105000  \n",
       "1346      6   2006        WD         Normal     262500  \n",
       "490       6   2008        WD         Normal     115000  \n",
       "718       8   2008        WD         Normal     341000  \n",
       "214       3   2010        WD         Normal     161750  \n",
       "816       7   2006        WD         Normal     137000  \n",
       "1161     11   2008        WD         Normal     224000  \n",
       "413       3   2010        WD         Normal     115000  \n",
       "1069      5   2007        WD         Normal     135000  \n",
       "854       7   2006        WD        Abnorml     170000  \n",
       "1447     12   2007        WD         Normal     240000  \n",
       "1431     10   2009        WD         Normal     143750  \n",
       "769       6   2010        WD         Normal     538000  \n",
       "1378      6   2006        WD         Normal      83000  \n",
       "952       4   2009        WD         Normal     133900  \n",
       "1239     12   2007        WD         Normal     265900  \n",
       "258       5   2008        WD         Normal     231500  \n",
       "1019      4   2006        WD         Normal     213490  \n",
       "838       6   2008        WD         Normal     144000  \n",
       "\n",
       "[20 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ames_iowa_housing.csv')\n",
    "\n",
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KP3ImCtGK1uo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     588 non-null    object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjxpXT4xK1uo"
   },
   "source": [
    "Разобьём данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aoC9zcGAK1uo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : (1168, 80) (1168,)\n",
      "Test : (292, 80) (292,)\n"
     ]
    }
   ],
   "source": [
    "target_column = \"SalePrice\"\n",
    "np.random.seed(seed)\n",
    "\n",
    "test_size = 0.2\n",
    "data_train, data_test, Y_train, Y_test = train_test_split(\n",
    "    data[data.columns.drop(\"SalePrice\")],\n",
    "    np.array(data[\"SalePrice\"]),\n",
    "    test_size=test_size,\n",
    "    random_state=seed)\n",
    "\n",
    "print(f\"Train : {data_train.shape} {Y_train.shape}\")\n",
    "print(f\"Test : {data_test.shape} {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNCvCJaAK1uo"
   },
   "source": [
    "Среди признаков нам встретятся как вещественные, так и категориальные. Пока что выделим в качестве категориальных те, значениями которых являются не числа, а какие-то другие сущности (но имейте в виду, что численные с виду признаки тоже могут быть категориальными)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QK9MTesIK1up",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous : 37, Categorical : 43\n"
     ]
    }
   ],
   "source": [
    "continuous_columns = [key for key in data.keys() if data[key].dtype in (\"int64\", \"float64\")]\n",
    "categorical_columns = [key for key in data.keys() if data[key].dtype == \"object\"]\n",
    "\n",
    "continuous_columns.remove(target_column)\n",
    "\n",
    "print(f\"Continuous : {len(continuous_columns)}, Categorical : {len(categorical_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEjtSzMcK1up"
   },
   "source": [
    "Посмотрим на заголовки признаков. В целом, многие названия вполне говорящие, и можно догадаться, что стоит за этими признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L_PprkEPK1up",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'MSSubClass',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'MasVnrArea',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageYrBlt',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'MiscVal',\n",
       " 'MoSold',\n",
       " 'YrSold']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSh9iDYUK1up"
   },
   "source": [
    "Одна из целей этого ноутбука — познакомить вас с fit-predict (fit-transform) интерфейсом, типичным для многих реализаций моделей машинного обучения и для различных инструментов работы с данными.\n",
    "\n",
    "Множество фреймворков машинного обучения (например, scikit-learn, CatBoost) содержат в себе модели и алгоритмы, которые описаны в виде классов, у которых есть два ключевых метода: fit и predict (transform). Давайте разберёмся, что делают эти методы.\n",
    "\n",
    "***fit*** — метод для обучения алгоритма. Он получает на входе данные и таргеты для обучения, после чего обновляет состояние класса. После использования метода fit считается, что объект класса готов к использованию. Внутри этого метода может быть что угодно: обучение модели, подбор гиперпараметров, подсчет статистик и т. д.\n",
    "\n",
    "***predict*** — метод для предсказания , обученного с помощью _fit_. В задаче регрессии это оценка параметра, в задаче классификации предсказанный класс.\n",
    "\n",
    "***transform*** — стилистический синоним _predict_, но используется в классах, которые реализуют преобразования данных, например, масштабирование признаков или кодирование категориальных фичей.\n",
    "\n",
    "***fit_transform*** — метод который учится на данных, а потом их же преобразовывает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QVOr2SrK1up"
   },
   "source": [
    "### 1. Базовая предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWi5LNwHK1up"
   },
   "source": [
    "Отметим два важных свойства линейной регрессии:\n",
    "\n",
    "- строго говоря, она умеет работать только с вещественными признаками\n",
    "- если признаки имеют разный масштаб при сопоставимой важности, регрессия может проигнорировать те, что имеют меньший масштаб\n",
    "\n",
    "Первое соображение заставляет придумывать способы борьбы с категориальными признаками, и мы начнём с самого простого: проигнорируем их.\n",
    "\n",
    "Второе соображение приводит к необходимости приводить признаки к одному масштабу (\"нормализовать фичи\"). В `sklearn` для этого есть два основных класса:\n",
    "\n",
    "- [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) - в каждой колонке вычитает среднее и делит на стандартное отклонение.\n",
    "- [sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) - в каждой колонке вычитает минимальное значение и делит на разницу между минимальным и максимальным.\n",
    "\n",
    "Применяются они в соответствии с описанной выше философией. Например:\n",
    "\n",
    "```\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "Обратите внимание, что scaler настраивается на обучающей выборке (именно по ней вычисляются среднее и стандартное отклонение), а к тестовой он применяется с уже подсчитанными статистиками.\n",
    "\n",
    "**Вопрос**. А зачем? Почему бы не нормировать отдельно обучающую и тестовую выборку? Почему бы не настроить наш scaler на объединении двух выборок? Ведь благодаря большему количеству данных мы бы настроили его точнее!\n",
    "<p>\n",
    "<details>\n",
    "  <summary>Кликните, чтобы узнать ответ</summary>\n",
    "\n",
    "Если мы по-разному отнормируем обучающую и тестовую выборки, то нам будет весьма сложно применять модель, обученную на одной из них, к другой. Это просто не будет иметь физического смысла.\n",
    "\n",
    "Настраивать что-либо на тестовой выборке — это очень плохая идея. Тестовая выборка должна быть неким независимым мерилом качества наших усилий по предсказанию, а если мы разрешим информации о распределении признаков в тестовой выборке \"протечь\" в процесс обучения, то мы эту независимость испортим.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "refOuBa2K1up"
   },
   "source": [
    "Итак, мы решили делать преобразование данных, которое состоит в:\n",
    "\n",
    "- сохранении лишь непрерывных фичей;\n",
    "- нормализации этих фичей (давайте остановимся на [sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html))\n",
    "\n",
    "В этом пункте вам нужно будет сделать класс такой предобработки данных, причём оформим мы его в виде класса с интерфейсом fit-transform.\n",
    "\n",
    "Несколько важных соображений:\n",
    "\n",
    "1. В прошлой лабораторной метод fit у нас ничего не возвращал, но правильнее сделать так, чтобы метод fit возвращал сам класс. В частности, это позволит нам писать model = model.fit().\n",
    "\n",
    "2. Первоначальный анализ данных удобно делать, когда они лежат в pd.DataFrame, т к у этого класса много методов, которые малым количеством телодвижений позволяют считать статистики и строить графики. Модели же проще учить, когда данные лежат в np.array, потому большое количество библиотек, где реализованы алгоритмы машинного обучения совместимы именно с numpy. Поэтому сделайте так, чтобы метод transform получал на вход pd.Dataframe, а возвращал np.array.\n",
    "\n",
    "3. В sklearn есть классы, от которых можно отнаследоваться, чтобы сделать класс с [fit-predict](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin) или [fit-transform](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) интерфейсом. Это очень полезно, т к позволит вам в дальнейшем пользоваться методами [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) и подобными. В этом пункте отнаследуйтесь от второго.\n",
    "\n",
    "4. У метода __init__ должен быть параметр ```needed_columns=None```. Туда передается список колонок, которые нужно взять из датафрейме. Делать это надо в ```fit``` и ```transform```. В случае если если он равен None, то класс оставляет все колонки из исходного набора данных.\n",
    "\n",
    "5. Обратите внимание, что достаточно реализовать `fit` и `transform`, а метод `fit_transform` из них слепит родительский класс.\n",
    "\n",
    "**Готовый препроцессор вам нужно будет сдать в Контест**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "deONxYcGK1uq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class BaseDataPreprocessor(TransformerMixin):\n",
    "    def __init__(self, needed_columns: Optional[List[str]]=None):\n",
    "        \"\"\"\n",
    "        :param needed_columns: if not None select these columns from the dataframe\n",
    "        \"\"\"\n",
    "        self.scaler = StandardScaler()\n",
    "        self.columns = needed_columns\n",
    "\n",
    "    def fit(self, data, *args):\n",
    "        \"\"\"\n",
    "        Prepares the class for future transformations\n",
    "        :param data: pd.DataFrame with all available columns\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        # Your code here\n",
    "            \n",
    "        if all(self.columns):\n",
    "            self.needed_continuous_columns = [key for key in self.columns if data[key].dtype in (\"int64\", \"float64\")]\n",
    "            self.scaler.fit(data[self.needed_continuous_columns])\n",
    "        else:\n",
    "            self.columns = data.keys()\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, data: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Transforms features so that they can be fed into the regressors\n",
    "        :param data: pd.DataFrame with all available columns\n",
    "        :return: np.array with preprocessed features\n",
    "        \"\"\"\n",
    "        # Your code here\n",
    "        return np.array(self.scaler.transform(data[self.needed_continuous_columns]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKeWoQ1SK1uq"
   },
   "source": [
    "**1. Сдайте вашу реализацию в Контест, задача «Простая предобработка».**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "-4LkDFASK1uq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = BaseDataPreprocessor(needed_columns=continuous_columns)\n",
    "\n",
    "data_train[continuous_columns] = data_train[continuous_columns].fillna(data_train[continuous_columns].median())\n",
    "data_test[continuous_columns] = data_test[continuous_columns].fillna(data_test[continuous_columns].median())\n",
    "\n",
    "X_train = preprocessor.fit_transform(data_train)\n",
    "X_test = preprocessor.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p14ruXEjK1uq"
   },
   "source": [
    "### 1.2 Умная предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8erGdYK-K1uq"
   },
   "source": [
    "Теперь давайте попробуем сделать что-нибудь поинтереснее. Для того, чтобы будущие алгоритмы регрессии работали хорошо, они должны обучаться и предсказывать на информативных фичах. Зачастую оказывается гораздо продуктивнее потратить какое-то время на изучение предметной области и придумывание хороших фичей (feature engineering), нежели жадно перебирать все известные алгоритмы машинного обучения.\n",
    "В этом пункте попробуйте придумать новых фичей и написать новый класс предобработки данных, который их добавляет (а, возможно, и убирает ещё какие-то старые).\n",
    "\n",
    "В конце этого пункта в раскрывашке перечислены наши идеи относительно того, что можно было добавить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ob8_T-DRK1uq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SmartDataPreprocessor(TransformerMixin):\n",
    "    # <Your ideas here>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ceqVElj8K1uq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SmartDataPreprocessor() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m \u001b[43mSmartDataPreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeded_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinuous_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_train \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mfit_transform(data_train)\n\u001b[0;32m      4\u001b[0m X_test \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(data_test)\n",
      "\u001b[1;31mTypeError\u001b[0m: SmartDataPreprocessor() takes no arguments"
     ]
    }
   ],
   "source": [
    "preprocessor = SmartDataPreprocessor(needed_columns=continuous_columns)\n",
    "\n",
    "X_train = preprocessor.fit_transform(data_train)\n",
    "X_test = preprocessor.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCZ-Ud9OK1ur"
   },
   "source": [
    "<details>\n",
    "  <summary>Пара простых идей. Кликните, когда будете готовы</summary>\n",
    "\n",
    "Например в датасете есть координаты квартиры, которые по идее сами по себе мало чего дают нашему регрессору. С другой стороны, по ним можно оценить центр города (или просто найти его на карте) и использовать в качестве фичи расстояние до центра города, которое может естественным образом влиять на цену жилья.\n",
    "\n",
    "Ещё может быть полезным почистить пропуски. И тут есть хитрость. Если вы просто вызовете data.info(), то вам покажется, что пропусков нет, но они могут приходить под разными обличьями. Например, у 490 объектов параметр Lot_Frontage (площадь фасада) равен нулю. Неожиданно, правда? Возможно, мы хотим эти нулевые значения заменить чем-нибудь, скажем, медианой.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIt68R29K1ur"
   },
   "source": [
    "### 2. Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ydi2yHwqK1ur"
   },
   "source": [
    "Давайте получим базовое решение (бейзлайн), чтобы потом с ним можно было сравниваться.\n",
    "\n",
    "Обучите линейную регрессию на обучающей выборке (которую мы подвергли преобразованию BaseDataPreprocessor). В библиотеке Sklearn есть релизация [без регуляризации](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression), [с L2-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) и [с L1-регуляризацией](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso).\n",
    "\n",
    "Начнём с обычной регрессии. Получите предсказания на тестовых данных и оцените на них качество модели. В качестве метрики оценки качества возьмите [средний модуль отклонения](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html) (mean absolute error, MAE). Как вам кажется, насколько хорошей вышла модель?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "d8AAt9_tK1ur",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22659.848657557515\n"
     ]
    }
   ],
   "source": [
    "## <YOUR CODE HERE>\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "reg = LinearRegression().fit(X_train, Y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print(mean_absolute_error(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "js3L8W-AK1ur"
   },
   "source": [
    "Теперь попробуйте L2-регуляризованную модель Ridge(). Какие значения метрик она даёт?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XnMAW-74K1ur",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22591.897238575286\n"
     ]
    }
   ],
   "source": [
    "## <YOUR CODE HERE>\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "reg2 = Ridge(alpha=6.0).fit(X_train, Y_train)\n",
    "y_pred2 = reg2.predict(X_test)\n",
    "print(mean_absolute_error(Y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s940mdAmK1ur"
   },
   "source": [
    "В целом, регуляризация редко портит модель, но важно правильно подобрать коэффициент регуляризации. Как именно — поговорим дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iTC8BpaK1ur"
   },
   "source": [
    "### 3. Выбор метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpjjz37cK1ur"
   },
   "source": [
    "Средний модуль ошибки (MAE) — в целом довольно хорошая метрика для задачи регрессии, потому что ее довольно легко проинтерпретировать. Но с ней есть одна проблема: ошибиться на $ 10 000 $ USD в предсказании цены квартиры стоимостью $ 100 000 $ USD страшнее чем допустить такую ошибку в предсказании цены жилья за $ 700 000 $ USD. Иными словами более показательной метрикой будет не абсолютная  ошибка $ error_i = |y_i - \\hat{y_i}|$, а логарифм относительной ошибки $error_i = log \\frac{y_i}{\\hat{y_i}} $. Также давайте обычное усреднение по всем примерам в тестовой выборке заменим на среднеквадратичное $ \\frac{1}{N} \\sum_i^{test} {error_i} \\longrightarrow \\sqrt{\\frac{1}{N} \\sum_i^{test}{(error_i)^2}}$. Итоговая метрика получается равной:\n",
    "\n",
    "$$\n",
    "Metric = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (log(y_i) - log(\\hat{y_i}))^2}\n",
    "$$\n",
    "\n",
    "Логично? Да. Но возникает еще одна проблема. Логарифм нельзя брать от отрицательного числа. Бороться с этим можно двумя способами.\n",
    "- Случай когда отрицательное число затисалось в target-ax не очень разумен, т. к. цена на дом не может быть отрицательной. В этом случае стоит кинуть ошибку, чтобы пользователь этой функции еще раз перепроверил правильные ли таргеты он подает.\n",
    "- В целом, у нас нет гарантий того, что наша модель (например линейная) предсказывает только положительные числа. Брать логарифм от отрицательного числа не получится, но качество такой модели все еще надо оценить. Давайте все предсказания, которые меньше некоторого порога $ a_{min} $, заменять этим порогом ($ \\hat{y_i} \\longleftarrow max(\\hat{y_i}, a_{min}) $), после чего подавать их в метрику. Для прохождения тестов возьмите $ a_{min} = 1 $.\n",
    "\n",
    "**2. Реализуйте эту метрику и сдайте в контест**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OAgpUi26K1ur",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.260793790218735"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def root_mean_squared_logarithmic_error(y_true, y_pred, a_min=1.):\n",
    "    # <Your code here>\n",
    "    if np.min(y_true) < 0:\n",
    "        raise ValueError('check your y_true')\n",
    "        \n",
    "    y_pred[y_pred < a_min] = a_min \n",
    "    \n",
    "    metric = np.sqrt(np.mean((np.log(y_true)-np.log(y_pred))**2))\n",
    "    return metric\n",
    "\n",
    "root_mean_squared_logarithmic_error(Y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UABi31oTK1ur"
   },
   "source": [
    "### 4. Логарифмирование таргета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yns3YwN-K1ur"
   },
   "source": [
    "Вообще идея с логарифмированием таргета довольно хороша для этой задачи. Давайте посмотрим на распределение обычных и логарифмированных таргетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JWb77b3uK1us",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_target_distribution(Y_train, Y_test, ax, n_bins=20):\n",
    "    ax.hist(Y_train, bins=n_bins, label=\"train\", color=\"red\", alpha=0.3, density=True)\n",
    "    ax.hist(Y_test, bins=n_bins, label=\"test\", color=\"blue\", alpha=0.3, density=True)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "\n",
    "\n",
    "def plot_both_distributions(Y_train, Y_test):\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, nrows=1, figsize=(15, 6))\n",
    "\n",
    "    plot_target_distribution(Y_train, Y_test, ax=ax0)\n",
    "    ax0.set_title(\"Standard\")\n",
    "\n",
    "    plot_target_distribution(np.log(Y_train), np.log(Y_test), ax=ax1)\n",
    "    ax1.set_title(\"Logarithmic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IOkOnHqKK1uv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_both_distributions(Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sdqyU7tK1uv"
   },
   "source": [
    "Как видите, если прологарифмировать таргеты, то их распределение станет более похоже на гауссовское. Интуиция подсказывает, что линейная регрессия с MSE loss-функцией должна лучше учиться на таких таргетах.\n",
    "\n",
    "Попробуйте написать класс, который во время обучения логарифмирует таргет, а во время предсказания — наоборот, экспоненциирует. После чего обучите оба метода на обучающих данных и сравните значения метрик MAE и MSLE на тесте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qyR7QyiK1uv"
   },
   "source": [
    "Что должно быть в этом классе:\n",
    "- Класс должен называться ```ExponentialLinearRegression```\n",
    "- Класс должен иметь такой же fit-predict интерфейс, как и было до этого. На вход он получает оригинальные X и Y, а уже внутри происходит логарифмирование или экспоненциирование.\n",
    "- Внутри этой модели будет работать [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). Хочется, чтобы этому классу можно было передавать аргументы инициализации с помощью *args и **kwargs\n",
    "- Чтобы потом этот класс можно было использовать в [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) в следующих пунктах, у него должны быть реализованы 5 методов\n",
    "    1. ```__init__(self, *args, **kwargs)``` - все полученные аргументы передаются дальше в Ridge.\n",
    "    2. ```fit(self, X, Y)``` - обучает класс, возвращает self.\n",
    "    3. ```predict(self, X)``` - делает предсказание.\n",
    "    4. ```get_params(deep=True)``` - возвращает dict с параметрами модели. Больще подробностей [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
    "    5. ```set_params(**params)``` - передает нужные параметры в модель. Больше подробносте [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)\n",
    "- Есть два подхода к тому как сделать все нужные методы:\n",
    "    - Отнаследоваться от класса Ridge и переопределить методы fit и predict, внутри вызывая super() от отцовского класса.\n",
    "    - Отнаследоваться от класса RegressorMixin и внутренним атрибутом класса сделать Ridge. Тогда все методы нужно будет писать руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IOnOVLY_K1uv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "class ExponentialLinearRegression(Ridge):\n",
    "    def __init__(self, alpha=1.0, fit_intercept=True, copy_X=True, max_iter=None, tol=0.0001, solver='auto', positive=False, random_state=None):\n",
    "        super().__init__(alpha=alpha, fit_intercept=fit_intercept, copy_X=copy_X, max_iter=max_iter, tol=tol, solver=solver, positive=positive, random_state=random_state)\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        super().fit(X, np.log(Y))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.exp(super().predict(X))\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return super().get_params(deep=deep)\n",
    "\n",
    "    def set_params(self, **kwargs):\n",
    "        super().set_params(**kwargs)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfGTYwdMK1uv"
   },
   "source": [
    "**3. Реализуйте этот класс и сдайте в контест**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cBnuMKpTK1uv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  : Classic : 22661.216200193474  Exponential : 18175.618819867657\n",
      "MSLE : Classic : 0.26727175206438814 Exponential : 0.14448960316961884\n"
     ]
    }
   ],
   "source": [
    "classic_regressor = Ridge()\n",
    "exponential_regressor = ExponentialLinearRegression()\n",
    "\n",
    "classic_regressor.fit(X_train, Y_train)\n",
    "exponential_regressor.fit(X_train, Y_train)\n",
    "\n",
    "classic_prediction = classic_regressor.predict(X_test)\n",
    "exponential_prediction = exponential_regressor.predict(X_test)\n",
    "\n",
    "print(f\"MAE  : Classic : {mean_absolute_error(Y_test, classic_prediction)}  Exponential : {mean_absolute_error(Y_test, exponential_prediction)}\")\n",
    "print(f\"MSLE : Classic : {root_mean_squared_logarithmic_error(Y_test, classic_prediction)} Exponential : {root_mean_squared_logarithmic_error(Y_test, exponential_prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mL9H6Fe0K1uw"
   },
   "source": [
    "Иногда получается так, что разные обученные вами модели приводят к улучшению одних метрик и ухудшению других. Это абсолютно нормально и этому не надо удивляться.\n",
    "\n",
    "Также зачастую случается так, что прирост по метрике не очень большой. И вы можете захотеть убедиться, что это реальное улучшение, а не просто случайная флуктуация. Для этого можно использовать подсчёт метрики про кросс-валидации (подробнее о ней можно почитать в соответствующей главе учебника). Суть метода в следующем:\n",
    "\n",
    "- мы разбиваем (случайным образом!) доступную нам выборку на $K$ (часто $K=5$) частей, которые называются _фолдами_\n",
    "- мы обучаем нашу модель $K$ раз, уча на всех фолдах, кроме одного, а на этом одном тестируя\n",
    "- мы получаем $K$ значений метрики, которые вместе дают нам лучшее представление о том, как ведёт себя модель на разных разбиениях на трейн и тест. В качестве итоговой метрики можно, к примеру, взять среднее полученных значений\n",
    "\n",
    "Сделать всё это можно с помощью обёртки [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), в которую можно подать модель, датасет и интересующую вас метрику. При этом оценку по кросс-валидации можно делать на всей доступной у вас выборке (ибо кросс-валидация уже включает разбиение на трейн и тест).\n",
    "\n",
    "Вычислите оценки MAE по кросс-валидации обычной (не регуляризованной) линейной регрессии и ExponentialLinearRegression на объединении обучающей и тестовой выборок.\n",
    "\n",
    "**4. Посчитайте и сдайте две оценки по кросс-валидации в Контест**.\n",
    "\n",
    "По шагам вам нужно\n",
    "1. Применить BaseDataPreprocessor к исходным данным\n",
    "2. Объединить трейн и тест\n",
    "3. Для первого числа использовать LinearRegression()\n",
    "4. Для второго -ExponentialLinearRegression с Ridge()\n",
    "5. Разбиение на фолды сделать с помощью `cv=KFold(n_splits=5, shuffle=True, random_state=42)`\n",
    "\n",
    "Обратите внимание, что параметр scoring — это не совсем функция-метрика, а немного более сложный объект, который можно соорудить, например, с помощью обёртки [make_scorer](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html#sklearn.metrics.make_scorer).\n",
    "\n",
    "Также имейте в виду, что, вообще говоря, с дефолтным значением параметра `cv` кросс-валидация разбивает датасет на фолды детерминированным образом. Если вам нужно случайное разбиение, то в качестве cv стоит подать объект класса `sklearn.model_selection.KFold` или `sklearn.model_selection.StratifiedKFold`. Используйте\n",
    "\n",
    "```\n",
    "cv=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtgOlv6tK1uw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Также при написании кода для кросс-валидации вам может пригодиться знание о пайплайнах.\n",
    "\n",
    "Представьте ситуацию. Прошел месяц с того момента, как вы построили модель, а теперь вам надо дообучить её на новых данных и активно применять для предсказания. Если вы не позаботились об инфраструктуре, то вам придётся рыскать по всему ноутбуку в поисках того, как вы предобрабатывали данные, какую модель учили, обязательно что-нибудь забудете и будете очень страдать. Поэтому человечество придумало пайплайны, которые позволяют объединить предобработку данных и обучение модели в один класс - pipeline. Его можно писать самому, либо взять из sklearn ([link](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "u3e3dNSaK1uw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22245.2349277838\n",
      "19527.773156477902\n"
     ]
    }
   ],
   "source": [
    "## <YOUR CODE HERE>\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "continuous_columns = [key for key in data.keys() if data[key].dtype in (\"int64\", \"float64\")]\n",
    "categorical_columns = [key for key in data.keys() if data[key].dtype == \"object\"]\n",
    "continuous_columns.remove(target_column)\n",
    "preprocessor = BaseDataPreprocessor(needed_columns=continuous_columns)\n",
    "data_train[continuous_columns] = data_train[continuous_columns].fillna(data_train[continuous_columns].median())\n",
    "data_test[continuous_columns] = data_test[continuous_columns].fillna(data_test[continuous_columns].median())\n",
    "\n",
    "X_train = preprocessor.fit_transform(data_train)\n",
    "X_test = preprocessor.transform(data_test)\n",
    "\n",
    "\n",
    "X = np.vstack([X_train, X_test])\n",
    "Y = np.hstack([Y_train, Y_test])\n",
    "\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "exponential_regressor = ExponentialLinearRegression()\n",
    "\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=True)\n",
    "print(np.mean(cross_val_score(linear_regressor, X, Y, scoring=mae_scorer, cv=KFold(n_splits=5, shuffle=True, random_state=42))))\n",
    "print(np.mean(cross_val_score(exponential_regressor, X, Y, scoring=mae_scorer, cv=KFold(n_splits=5, shuffle=True, random_state=42))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjFgAA4YK1uw"
   },
   "source": [
    "### 5. Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siKQL7pIK1uw"
   },
   "source": [
    "Линейную регрессию почти всегда можно улучшить с помощью регуляризации. Но при этом у нас возникает **гиперпараметр** — коэффициент регуляризации, и подбирать его нужно правильно. Более подробно о подборе гиперпараметров вы можете прочитать в соответствующей главе учебника), а пока мы разберём самые базовые подходы.\n",
    "\n",
    "В этой лабораторной вы познакомитесь с самым тривиальным способом — подбором по сетке. В данном случае это значит, что мы фиксируем несколько значений коэффициента регуляризации ```alpha``` и просто для каждого из них смотрим, что получится. Но важно отметить, что коэффициенты регуляризации стоит перебирать по _логарифмической_ сетке, например: `1e-2, 1e-1, 1, 1e+1, 1e+2`.\n",
    "\n",
    "Разобравшись, что перебирать, перейдём к вопросу о том, как оценивать. Есть два основных подхода:\n",
    "\n",
    "*   Train-Val-Test split. Датасет делится на три части, на одной модели учатся, на другой подбираются гиперпараметры, на третьей считаются финальные метрики. Этот метод довольно шумный, зато быстрый.\n",
    "*   Кроссвалидация. Она значительно дольше, но надёжней. В этом пункте мы воспользуемся именно ей.\n",
    "\n",
    "\n",
    "Возьмите класс [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) из scikit-learn и с его помощью подберите гиперпараметр ```alpha``` для линейной регрессии с L2-регуляризацией (соответствующий класс зовут Ridge). Возможно, для минимизации разных метрик (_root_mean_squared_logarithmic_error_ и _mean_absolute_error_) понадобятся разные значения гиперпараметров. Выберите из сетки ```np.logspace(-3, 3, num=7, base=10.)``` значение, которое максимизирует _root_mean_squared_logarithmic_error_ для _ExponentialLinearRegression_ и\n",
    "\n",
    "**5. Загрузите оптимальное значение коэффициента регуляризации в Контест**.\n",
    "\n",
    "Параметр `cv` оставьте дефолтным или возьмите `cv=5` (результат не поменяется). Будьте внимательны: по умолчанию `best_score_` у `GridSearchCV` - это _самое большое значение_. Чтобы не попасться в эту ловушку, обратите внимание на параметр `greater_is_better` функции `make_scorer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "c_otnmqyK1uw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00140076, 0.00159588, 0.00159593, 0.00139632, 0.0009975 ,\n",
      "       0.0010076 , 0.00099716]), 'std_fit_time': array([4.94077173e-04, 4.88636667e-04, 4.88091465e-04, 7.96962004e-04,\n",
      "       3.50402318e-07, 1.24201206e-05, 6.67572021e-07]), 'mean_score_time': array([0.00059829, 0.        , 0.00039935, 0.00059829, 0.        ,\n",
      "       0.00019917, 0.0001997 ]), 'std_score_time': array([0.0004885 , 0.        , 0.0004891 , 0.0004885 , 0.        ,\n",
      "       0.00039835, 0.0003994 ]), 'param_alpha': masked_array(data=[0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.001}, {'alpha': 0.01}, {'alpha': 0.1}, {'alpha': 1.0}, {'alpha': 10.0}, {'alpha': 100.0}, {'alpha': 1000.0}], 'split0_test_score': array([-0.12748943, -0.12748949, -0.12749006, -0.12749582, -0.12755552,\n",
      "       -0.12819732, -0.13816579]), 'split1_test_score': array([-0.21321997, -0.21322   , -0.2132203 , -0.21322324, -0.21325319,\n",
      "       -0.21345334, -0.21359368]), 'split2_test_score': array([-0.13810253, -0.13810211, -0.13809792, -0.13805641, -0.13767533,\n",
      "       -0.13592554, -0.14707248]), 'split3_test_score': array([-0.15471534, -0.15471484, -0.1547099 , -0.15466102, -0.15422081,\n",
      "       -0.15246578, -0.16196332]), 'split4_test_score': array([-0.14449766, -0.14449759, -0.14449684, -0.1444896 , -0.14444243,\n",
      "       -0.14533116, -0.16711256]), 'mean_test_score': array([-0.15560499, -0.15560481, -0.155603  , -0.15558522, -0.15542946,\n",
      "       -0.15507463, -0.16558157]), 'std_test_score': array([0.0301346 , 0.03013466, 0.03013524, 0.03014094, 0.03019246,\n",
      "       0.03032785, 0.02613354]), 'rank_test_score': array([6, 5, 4, 3, 2, 1, 7])}\n"
     ]
    }
   ],
   "source": [
    "## <YOUR CODE HERE>\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "parameters = {'alpha':np.logspace(-3, 3, num=7, base=10.)}\n",
    "\n",
    "rmsle_scorer = make_scorer(root_mean_squared_logarithmic_error, greater_is_better=False)\n",
    "\n",
    "elr = ExponentialLinearRegression()\n",
    "reg = GridSearchCV(elr, parameters, scoring=rmsle_scorer)\n",
    "reg.fit(X, Y)\n",
    "print(reg.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUYa5U1gK1uw"
   },
   "source": [
    "### 6. Линейная модель своими руками\n",
    "\n",
    "В этом разделе вы напишете собственный класс линейной модели, чтобы лучше разобраться, как работает обучение с помощью SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-d2onzaK1uw"
   },
   "source": [
    "Линейная модель делает предсказание по такой формуле:\n",
    "$$\n",
    "\\hat{y_i} = \\langle \\vec{w}, \\vec{x_i} \\rangle + b\n",
    "$$\n",
    "Здесь $\\vec{w}$ и b - обучаемые параметры. $\\vec{x_i}$ - вектор фичей данного примера.\n",
    "$\\vec{w}$ и b находятся из задачи минимизации лосс функции:\n",
    "\n",
    "$$\n",
    "\\vec{w}, b = {argmin}_{\\vec{w}, b}(L) \\ ; \\ L = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2 + \\lambda \\vec{w}^T\\vec{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMisQdSGK1uw"
   },
   "source": [
    "Задачу минимизации лосс функции мы будем решать градиентным спуском. Для этого надо найти градиенты лосса по параметром модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaB_KihjK1uw"
   },
   "source": [
    "$$\n",
    "\\nabla_b L = \\frac{2}{N} sum(X \\vec{w} + b - \\vec{y})\\\\\n",
    "\\nabla_{\\vec{w}} L = \\frac{2}{N} X^T(X \\vec{w} + b - \\vec{y}) + 2\\lambda \\vec{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ka0Q5OI6K1ux"
   },
   "source": [
    "Теперь давайте реализуем этот алгоритм ввиде класса с методами fit-predict.\n",
    "Что в нем должно быть:\n",
    "1. Класс должен называться ```SGDLinearRegressor```\n",
    "2. Класс должен быть отнаследован от sklearn-овского класса [RegressorMixin](https://scikit-learn.org/stable/modules/generated/sklearn.base.RegressorMixin.html)\n",
    "3. Класс должен инициализироваться со следующими гиперпараметрами:\n",
    "\n",
    "    a. ```lr``` — learning rate. Длина шага градиентного спуска\n",
    "\n",
    "    b. ```regularization``` — коэффициент λ из формулы выше\n",
    "    \n",
    "    c. ```delta_converged``` — устанавливает условие окончание обучение. В тот момент когда норма разности весов на соседних шагах градиентного спуска меньше чем ```delta_converged``` алгоритм перкращает обновлять веса\n",
    "    \n",
    "    d. ```max_steps``` — максимальное число шагов градиентного спуска\n",
    "    \n",
    "    e. ```batch_size``` — размер батча\n",
    "\n",
    "4. Реализуйте **стохастический** градиентный спуск. На каждом шагу градиентного спуска должен формироваться батч размера ```batch_size``` из матрицы признаков. Это нужно для того чтобы алгоритм быстрее сходился. Батч может выбираться случайно на каждом шаге градиентного спуска, либо каждую эпоху можно перемешивать трейн выборку и итерироваться батчами по ней."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFIb9mjWK1ux",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Обратите внимание при реализации SGD на следующие моменты (частые ошибки):\n",
    "* не перепутайте, какие коэффициенты в SGD стоят при самой функции потерь, а какие — при регуляризационном члене. Правильный вариант: $\\frac{\\alpha}{batch\\_size}$ при градиенте MSE, $\\alpha\\lambda$ при градиенте регуляризатора.\n",
    "* для остановки нужно сравнивать норму, а не ее квадрат\n",
    "* для правильного решения нужно не итерироваться по батчу,  а перемножать матрицы (иначе не зайдет по TL)\n",
    "* метод `predict` должен возвращать одномерный numpy array (не двумерный вектор-столбец формы (X.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "AYmQ4zSkK1ux",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import RegressorMixin, BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(24)\n",
    "\n",
    "class SGDLinearRegressor(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self, lr=0.002, regularization=1.33, delta_converged=1e-2, max_steps=1000, batch_size=64):\n",
    "        self.lr = lr\n",
    "        self.regularization = regularization\n",
    "        self.max_steps = max_steps\n",
    "        self.delta_converged = delta_converged\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        \n",
    "        self.grad_w=1000\n",
    "        self.grad_w=1000\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        self.W = np.random.rand(X.shape[1])\n",
    "        self.b = np.random.randn()\n",
    "        for e in range(self.max_steps):\n",
    "            shuffled_indices = np.random.permutation(X.shape[0])\n",
    "            self.X_shuffled = X[shuffled_indices]\n",
    "            self.Y_shuffled = Y[shuffled_indices]\n",
    "            for i in range(0, X.shape[0], self.batch_size):\n",
    "                X_batch = self.X_shuffled[i:i+self.batch_size]\n",
    "                y_batch = self.Y_shuffled[i:i+self.batch_size]\n",
    "                \n",
    "                self.grad_w  = 2 * self.lr * X_batch.T @ (np.dot(X_batch, self.W) - y_batch) *(1/ X_batch.shape[0]) + 2 * self.lr * self.regularization * self.W\n",
    "                self.grad_b = 2 * self.lr / self.batch_size * np.sum(X_batch @ self.W + self.b - y_batch)\n",
    "\n",
    "                \n",
    "\n",
    "                if np.linalg.norm(self.grad_w) < self.delta_converged:\n",
    "                    return self\n",
    "                \n",
    "                self.W -= self.grad_w\n",
    "                self.b -= self.grad_b\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.ravel(X @ self.W.T + self.b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "DanmLPpaK1ux",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292,) (292,)\n",
      "MAE :  23408.67431437166\n",
      "Mean log :  0.17797137615804284\n"
     ]
    }
   ],
   "source": [
    "# Check yourself\n",
    "\n",
    "model = SGDLinearRegressor()\n",
    "model.fit(X_train, Y_train)\n",
    "prediction = model.predict(X_test)\n",
    "print(Y_test.shape, prediction.shape)\n",
    "print(\"MAE : \", mean_absolute_error(Y_test, prediction))\n",
    "print(\"Mean log : \", root_mean_squared_logarithmic_error(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Эдуард\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1062: RuntimeWarning: overflow encountered in square\n",
      "  (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regularization': 8.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "np.random.seed(42)\n",
    "parameters = {'regularization':np.linspace(start=-10,stop=80,num=11)}\n",
    "             #'max_steps':np.linspace(start=100,stop=10000,num=5),\n",
    "             #}\n",
    "\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "sgd = SGDLinearRegressor()\n",
    "reg = GridSearchCV(sgd, parameters, scoring=mae_scorer)\n",
    "reg.fit(X_train, Y_train)\n",
    "print(reg.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdVXFO2aK1ux"
   },
   "source": [
    "### 7. Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npUKbcsbK1ux"
   },
   "source": [
    "В самом начале ноутбука мы отбросили категориальные фичи, хотя они могут помочь нам сделать модель лучше. Давайте же научимся ими пользоваться.\n",
    "\n",
    "Самый простой подход — это закодировать значения категориального признака числами, скажем, от $0$ до $C-1$, где $C$ — количество значений категориального признака. Иногда это может сработать, но для этого нужно, чтобы между значениями признака были определены отношения больше/меньше (такие признаки называются _ординальными_), причём соотношения между значениями должны быть более-менее линейными. В целом, не очень частая ситуация, поэтому так мы делать не будем.\n",
    "\n",
    "Вместо этого мы будем использовать OneHotEncoding. Пусть некоторая категориальная фича имеет $C$ уникальных значений. Давайте эту фичу закодируем в виде $C$ столбцов, каждый из которых соответствует некоторому уникальному значению категориальной фичи. Для каждого элемента выборки будем класть единичку в столбец, соответствующий этой фиче, и нолики в остальные.\n",
    "\n",
    "У этого метода есть недостаток. Если категориальная фича принимает слишком много значений, то вы нагенерируете много новых столбцов, каждый из которых будет содержать мало информации. Из-за них моделька может переобучиться.\n",
    "\n",
    "Этот метод имплементирован [здесь](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). У него есть пара важных гиперпараметров, которые стоит упомянуть:\n",
    "- ```handle_unknown``` - управляет обработкой незнакомых категорий на этапе `transform`. Число уникальных значений (и число столбцов) настраивается на обучающей выборке, и при дальнейшем применении может появиться значение, которого ещё не было. Если указать ```handle_unknown=\"ignore\"```, все поля для такого объекта будут заполнены нулями.\n",
    "- ```drop``` - если делать one-hot-encoding так как это описано выше, то сумма всех столбцов, соответствующих значениям категориальной фичи, будет равна единичному вектору. А такой вектор уже есть (он соответствует свободному члену). То есть признаки становятся линейно зависимыми, и это сломает процесс обучения линейной модели. Поэтому есть смысл для каждой фичи отбрасывать одну из получившихся колонок (```drop=\"first\"```) или хотя бы делать это только для бинарных фичей (```drop=\"if_binary\"```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0es5bKeK1ux"
   },
   "source": [
    "В этом пункте вам надо еще раз предобработать данные, добавив в них часть категориальных фичей, закодированных OneHotEncoding-ом. После этого обучите классификатор заново и выбейте лучшую метрику на тестовой выборке. А именно, мы добавим фичи \"Overall_Qual\", \"Garage_Qual\", \"Sale_Condition\", \"MS_Zoning\". Используйте значение параметра handle_unknown=\"ignore\".\n",
    "\n",
    "*На практике в некоторых версиях scikit-learn есть проблема с совместимостью `handle_unknown=\"ignore\"` и `drop=\"first\"` одновременно, поэтому вторым можно пожертвовать.\n",
    "\n",
    "Класс будет наследоваться от BaseDataPreprocessor, так что в него можно будет передавать нужные для BaseDataPreprocessor параметры. Также это позволит не переписывать заново то, что происходит в базовом классе, а просто взывать к ним с помощью конструкции `super`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v80RppKdK1ux"
   },
   "source": [
    "Обучите модель с добавленными категориальными фичами. Получилось ли улучшить её качество?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWYh1NPbK1uy"
   },
   "source": [
    "### 8. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlzhlXoLK1uy"
   },
   "source": [
    "Представьте ситуацию. Прошел месяц с того момента, как вы построили модель, а теперь вам надо дообучить её на новых данных и активно применять для предсказания. Если вы не позаботились об инфраструктуре, то вам придётся рыскать по всему ноутбуку в поисках того, как вы предобрабатывали данные, какую модель учили, обязательно что-нибудь забудете и будете очень страдать. Поэтому человечество придумало пайплайны, которые позволяют объединить предобработку данных и обучение модели в один класс — pipeline. Его можно писать самому, либо взять из sklearn ([link](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)).\n",
    "\n",
    "**7. Напишите пайплайн, объединяющий использованную нами базовую предобработку данных (BaseDataPreprocessor и OneHotPreprocessor), а также линейную регрессию с L2-регуляризацией, и сдайте его в Контест.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "a6udrWyYK1uy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def make_ultimate_pipeline():\n",
    "    # <YOUR CODE HERE>\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqmOG-epK1uz"
   },
   "source": [
    "В этом пункте вы попробуете сделать что-то поинтереснее и загрузите плоды ваших трудов в Контест.\n",
    "\n",
    "Попробуйте усовершенствовать предобработку данных, добавляя или выкидывая фичи, придумывая функции от признаков так, чтобы улучшить качество классификатора.\n",
    "\n",
    "Ещё несколько базовых идей о том, что можно было бы попробовать:\n",
    "\n",
    "- Постройте гистограммы значений признаков. Вы обнаружите, что некоторые из них почти всегда принимают одно и то же значение. Для начала их можно просто выкинуть.\n",
    "- Почистите выбросы. У некоторых объектов значения каких-то признаков могут сильно выбиваться, и это будет мешать регрессии обучиться. Вообще говоря, такие объекты можно выкидывать, но с текущей архитектурой пайплайна вам будет трудно это настроить. Так что вы можете пока заменять их на более разумные значения.\n",
    "- Мы добавили лишь несколько категориальных признаков, а на самом деле многие из них могут быть полезными.\n",
    "- Можно дискретизовать непрерывные фичи. Самый банальный пример: если непрерывная фича принимает всего несколько значений, её можно попробовать проинтерпретировать, как категориальную, и подать в one-hot энкодер. Но можно и как-то ещё разбивать по порогам.\n",
    "- Можно делать и более сложные преобразования. Например в датасете есть координаты квартиры, которые по идее сами по себе мало чего дают нашему регрессору. С другой стороны, по ним можно оценить центр города (или просто найти его на карте) и использовать в качестве фичи расстояние до центра города, которое может естественным образом влиять на цену жилья.\n",
    "- Не забывайте настраивать коэффициент регуляризации: для разных датасетов оптимальное значение будет разным.\n",
    "\n",
    "**В контест вам нужно будет сдать свой класс модели**. Он будет обучаться и тестироваться на новом и неизвестном вам разбиении датасета на трейн и тест по метрике `root_mean_squared_logarithmic_error`.\n",
    "В контесте будет специально проверено, что вы сдаёте именно `Pipeline`.\n",
    "\n",
    "Не забывайте, что вместе с пайплайном вам нужно отправить и все самописные классы, которые в нём участвуют.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
